We next applied Track2p to a longitudinal dataset consisting of daily recordings of the same 720×720 μm FOV throughout the second postnatal week of mouse barrel cortex development (postnatal days 8 (P8) to P14, n=7 imaging sessions from one mouse; for more details see Methods.) In addition to the calcium indicator (GCaMP8m), we virally expressed a sparse anatomical marker (tdTomato) targeting GABAergic neurons using conditional expression in GAD67-Cre mice. This dual-labelling strategy facilitated reliable FOV identification across sessions and provided an anatomical reference for Track2p’s initial cross-session registration and tracking (Fig. 3, for comparison with tracking based on GCaMP8m registration see the ‘Benchmarking on manually tracked cells’ section). Before running Track2p, each recording was preprocessed using Suite2p for active cell detection (segmentation) and calcium fluorescence trace extraction (see Methods). The outputs of Suite2p (ROIs, traces and FOV images) were then used as inputs to the Track2p algorithm.

We next analyzed the development of functional properties of the tracked population of neurons across the second postnatal week of mouse barrel cortex development. For this, we used a full dataset of 6 mice imaged daily for a minimum of 6 consecutive days within the second postnatal week (P7 to P14, see Fig. 5B for summary, we used this dataset for all subsequent analyses). On average 526 (± 190 std) neurons per mouse were successfully tracked across all days using Track2p, corresponding to 33 % (± 11 % std) of the neurons detected on the first day for each mouse. 

We assessed behavioural state indirectly using the videos capturing spontaneous mouse movement and quantifying them using a ‘motion energy’ metric.

Chronic 2-photon calcium imaging

Longitudinal two-photon calcium imaging was performed for each mouse for at least 6 consecutive days (see Fig. 5 for details). Imaging was performed using a Bruker (Ultima 2P) microscope with a Coherent Mai-Tai excitation laser (950 nm excitation light) and a 16x Nikon objective (NA 0.8). Before detection, emitted light was split into two optical paths each associated with a filter (red and green, 580-620 and 500-550 nm respectively), allowing us to simultaneously record the GCaMP8m and the tdTomato signal. The acquisition was performed using the Prairie view software. All recordings were performed in layer 2/3 (depth between 100-200 µm from the pial surface) with a 720 × 720 µm field of view and 512 × 512 pixel resolution. Imaging rate was 30 Hz (resonant scanner) and each session lasted 20 minutes. All experiments were performed in the dark, under sensory-minimised conditions, with mice being free to spontaneously run on a non-motorised treadmill (Luigs and Neumann). To facilitate alignment and cell tracking, we kept the alignment of the head mount with respect to the microscope fixed across all sessions for the same mouse. To record from the same region across days we manually aligned the imaging plane in x, y and z to best match the reference images of the red channel (tdTomato) from all previous recording days. During the course of each recording, pups were kept warm by a heating element mounted to the imaging setup. After each imaging session, the pups were returned to their home cage with the dam and their littermates.

Videography

All videography was performed using a Basler camera (Basler ACE2 1920), with an infrared LED light source (ThorLabs 850 nm) pointed at the mouse. Videos were recorded at 30 Hz, with the microscope acquisition acting as a trigger for camera frame acquisition, also allowing for simple synchronisation across the two modalities.

Processing of calcium imaging data

Calcium imaging data was preprocessed using the Suite2p pipeline, sequentially performing motion correction, ROI detection, signal extraction and spike deconvolution 23 for each recording separately. Suite2p additionally provides a cell classification feature, providing a probability of a classifier categorising an ROI as being a true cell. We considered all ROIs above the default threshold of 0.5 as true cells. We used baseline corrected fluorescence traces as our dF/F (using the default Suite2p parameters) for all subsequent analyses. To facilitate the use of Track2p with other preprocessing pipelines, we implemented a data loader that takes as input three simple NumPy arrays corresponding to ROIs, field of view and traces (for more information see: https://track2p.github.io/run_inputs_and_parameters).
Preprocessing videography

We used the global movements of the mouse as a proxy of its arousal state. Similarly as in 62 we quantified these by looking at the pixel-wise difference of consecutive frames in the videography recording. Namely, we first took each two consecutive frames, computed their pixelwise difference. We then squared all individual pixel-wise values and summed across pixels. This yielded a scalar value quantifying the motion of the mouse at each time point, which was used for all subsequent analyses.

Functional properties of tracked neurons
Calcium event rates

To quantify the calcium event rate statistics we used SciPy’s peak detection algorithm (Python). For this we first denoised the traces slightly by averaging using a bin size of 10 frames and then proceeded to detect any peaks with a height and prominence of at least one standard deviation. We then calculated the rate as the number of peaks per minute within the recording. When quantifying the stability of the rates across days we computed the Pearson correlation coefficient across all neurons for each possible combination of sessions recorded from the same mouse.

Decoding

All decoding was done using linear regression with ridge regularisation (ridge regression) to avoid overfitting given the large number of neurons. Ridge regression optimises the weights (β) that minimise the following loss function:

L(\beta) = \|y - X\beta\|_2^2 + \lambda\|\beta\|_2^2

Where in our case y is behavioural data, X is neural data and λ is a regularisation parameter. To choose the optimal λ and to reliably estimate the model performance on same-day decoding we used nested cross-validation (see for example 65,66), ensuring data efficiency and a splitting between training, validation and test data. Briefly, a grid search for the optimal λ is performed by using the train set to fit models with different λ values and choosing the value corresponding to the model with the best performance on the held out validation set (model selection). This model is then evaluated on the test data that was used neither in model fitting nor in the hyperparameter optimization (model evaluation). To ensure data efficiency, nested cross-validation repeats this procedure for all possible splits of the data, with an outer cross-validation loop used for model evaluation and an inner loop for model selection. We used 5 fold splits for both the inner and outer loops, splits were done on consecutive 2 minute blocks of the recording. For cross-day decoding we fit a new model with the optimal lambda for that given day and evaluated it on all other days. For all decoding analysis we slightly denoised the dF/F as well as the behaviour traces by averaging in bins of 10 consecutive timestamps. All models were implemented and fitted using PyTorch (Python).
