
# Setup
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import sys
import pickle
import argparse
import torch

from decoder import (
    train_decoder,
    predict,
    cross_validate_decoder,
    accuracy_all_sessions,
    print_data_summary,
    plot_trial,
    random_sample_trials,
    verify_data_format,
    train_validate_decoder, 
    get_trial_indices,
    f1scores_all_sessions
)

# Set random seed for reproducibility
np.random.seed(0)

# parse arguments
# usage:
# python train_decoder.py <data_file_path>
# options:
# --verify-only: only verify data format and print summary, then exit. 
# --plot-samples: plot sample trials from data and save to png files. 
# --cpu: force torch to use CPU only.
parser = argparse.ArgumentParser(description='Train and evaluate a neural decoder.')
parser.add_argument('data_file_path', type=str, help='Path to the data file (pickle format).')
parser.add_argument('--verify-only', action='store_true', help='Only verify data format and print summary, then exit.')
parser.add_argument('--plot-samples', action='store_true', help='Plot sample trials from data and save to png files.')
parser.add_argument('--cpu', action='store_true', help='Force torch to use CPU only.')

args = parser.parse_args()
data_file_path = args.data_file_path
verify_only = args.verify_only
plot_samples = args.plot_samples
use_cpu = args.cpu

nneurons_sample = 50
input_names = None
output_names = None
train_params = {
    'npcs': 100,
    'lr': 1e-3,
    'l1_weight': 1e-4,
    'balanced_loss': True,
}
if use_cpu:
    train_params['device'] = torch.device('cpu')

# load data
with open(data_file_path, 'rb') as f:
    data = pickle.load(f)

# check that the formatting is valid
valid, errors, warnings = verify_data_format(data)
if not valid:
    print("Data format is invalid. Errors:")
    for error in errors:
        print(f"  - {error}")
    sys.exit(1)
if warnings:
    print("Data format warnings:")
    for warning in warnings:
        print(f"  - {warning}")
else:
    print("Data format is valid, no errors or warnings.")        

# print summary of data
print_data_summary(data)

# plot sample trials
if plot_samples or verify_only:
    nplot = 4 # maximum number of trials to plot
    sessionplot,trialplot = random_sample_trials(data,nplot)
    fig,ax = plt.subplots(3,nplot,figsize=(30,15),sharex='col')
    for i in range(nplot):
        plot_trial(data,session=sessionplot[i],trial=trialplot[i],ax=ax[:,i],
                    input_names=data['input_names'],output_names=data['output_names'],
                    nneurons_sample=nneurons_sample)
        if i > 0:
            ax[1,i].set_yticklabels([])
            ax[2,i].set_yticklabels([])

    fig.suptitle('Sample Trials from Dataset')
    fig.tight_layout()
    fig.savefig('sample_trials.png', dpi=150)
    plt.close(fig)

if verify_only:
    print("Data verification complete.")
    sys.exit(0)

# train decoder on .7 of the data, test on .3
scores, predictions, pcs, confidences, train_idx, test_idx, model, output = train_validate_decoder(
    data['neural'], data['input'], data['output'],
    **train_params
)
# Compute chance performance for each output dimension using training data class fractions
num_classes = [len(data['output_values'][i]) for i in range(len(data['output_values']))]
chance_uniform = [1.0 / nc for nc in num_classes]  # Random uniform guessing

# Use class fractions from training data for chance computation
class_fractions = model['class_fractions']
chance_majority = [np.max(fracs) for fracs in class_fractions]  # Most common class proportion

test_predictions_only = get_trial_indices(predictions, test_idx)
test_output_only = get_trial_indices(output, test_idx)

train_predictions_only = get_trial_indices(predictions, train_idx)
train_output_only = get_trial_indices(output, train_idx)

train_balanced_accuracy = accuracy_all_sessions(train_predictions_only, train_output_only, balanced=True)
print("\nTraining Balanced Accuracy Scores (chance = 1/num_classes):")
for out_dim in range(len(train_balanced_accuracy)):
    print(f"  {out_dim} ({data['output_names'][out_dim]}): {train_balanced_accuracy[out_dim]:.4f}  (chance: {chance_uniform[out_dim]:.4f})")

balanced_accuracy = accuracy_all_sessions(test_predictions_only, test_output_only, balanced=True)
print("\nValidation Balanced Accuracy Scores (chance = 1/num_classes):")
for out_dim in range(len(balanced_accuracy)):
    print(f"  {out_dim} ({data['output_names'][out_dim]}): {balanced_accuracy[out_dim]:.4f}  (chance: {chance_uniform[out_dim]:.4f})")

# plot results for cross-validated model, same trials
if plot_samples:
    fig,ax = plt.subplots(3,nplot,figsize=(30,15),sharex='col')
    sessionplot,trialplot = random_sample_trials(data,nplot,trial_indices=test_idx)
    
    for i in range(nplot):
        plot_trial(data,session=sessionplot[i],trial=trialplot[i],ax=ax[:,i],
                    input_names=input_names,output_names=output_names,
                    nneurons_sample=nneurons_sample,
                    predictions=predictions)
        if i > 0:
            ax[1,i].set_yticklabels([])
            ax[2,i].set_yticklabels([])
    fig.suptitle('Predictions')
    fig.tight_layout()
    fig.savefig('predictions.png', dpi=150)
    plt.close(fig)
